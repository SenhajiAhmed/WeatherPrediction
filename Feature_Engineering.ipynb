{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1eb5348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original hourly data shape: (1740960, 12)\n",
      "Date range: 2025-01-01 00:00:00 to 2025-01-31 23:00:00\n",
      "\n",
      "Columns: ['valid_time', 'latitude', 'longitude', 't2m', 'd2m', 'msl', 'u10', 'v10', 'tcc', 'skt', 'number', 'expver']\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Load and prepare data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"era5_cleaned.csv\", parse_dates=['valid_time'])\n",
    "\n",
    "# Ensure chronological order\n",
    "df = df.sort_values(['longitude', 'latitude', 'valid_time']).reset_index(drop=True)\n",
    "\n",
    "print(f\"Original hourly data shape: {df.shape}\")\n",
    "print(f\"Date range: {df['valid_time'].min()} to {df['valid_time'].max()}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9a60771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of data with date:\n",
      "           valid_time        date  latitude  longitude        t2m\n",
      "0 2025-01-01 00:00:00  2025-01-01      20.0       -9.8  11.005524\n",
      "1 2025-01-01 01:00:00  2025-01-01      20.0       -9.8  10.411774\n",
      "2 2025-01-01 02:00:00  2025-01-01      20.0       -9.8   9.693756\n",
      "3 2025-01-01 03:00:00  2025-01-01      20.0       -9.8   9.174713\n",
      "4 2025-01-01 04:00:00  2025-01-01      20.0       -9.8   8.739410\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Create date column\n",
    "df['date'] = df['valid_time'].dt.date\n",
    "print(f\"Sample of data with date:\\n{df[['valid_time', 'date', 'latitude', 'longitude', 't2m']].head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28a56827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather parameters to aggregate (7): ['t2m', 'd2m', 'msl', 'u10', 'v10', 'tcc', 'skt']\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Identify weather parameters to aggregate\n",
    "# Exclude: coordinate columns, time columns, and metadata columns\n",
    "exclude_cols = ['valid_time', 'date', 'longitude', 'latitude', 'number', 'expver']\n",
    "weather_params = [col for col in df.columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"Weather parameters to aggregate ({len(weather_params)}): {weather_params}\")\n",
    "# Should be: t2m, d2m, msl, u10, v10, tcc, skt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cdc63b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily aggregated data shape: (72540, 24)\n",
      "\n",
      "Columns created: ['date', 'latitude', 'longitude', 't2m_min', 't2m_max', 't2m_mean', 'd2m_min', 'd2m_max', 'd2m_mean', 'msl_min', 'msl_max', 'msl_mean', 'u10_min', 'u10_max', 'u10_mean', 'v10_min', 'v10_max', 'v10_mean', 'tcc_min', 'tcc_max', 'tcc_mean', 'skt_min', 'skt_max', 'skt_mean']\n",
      "\n",
      "First few rows:\n",
      "         date  latitude  longitude   t2m_min    t2m_max   t2m_mean  d2m_min  \\\n",
      "0  2025-01-01      20.0      -9.80  8.079742  19.427155  13.512838 -2.99888   \n",
      "1  2025-01-01      20.0      -9.55  7.933746  19.434479  13.462057 -2.94028   \n",
      "2  2025-01-01      20.0      -9.30  7.940094  19.426666  13.453064 -2.86118   \n",
      "3  2025-01-01      20.0      -9.05  7.899078  19.409820  13.417399 -2.78550   \n",
      "4  2025-01-01      20.0      -8.80  7.849762  19.550446  13.468669 -2.77085   \n",
      "\n",
      "   d2m_max  d2m_mean    msl_min  ...  u10_mean   v10_min   v10_max  v10_mean  \\\n",
      "0 -0.61387 -2.062680  1017.8256  ... -4.516831 -3.625711 -2.103291 -3.016637   \n",
      "1 -0.58896 -2.064752  1017.8631  ... -4.365922 -3.698465 -2.200458 -3.106257   \n",
      "2 -0.54697 -2.052566  1017.8625  ... -4.277278 -3.767801 -2.321552 -3.189956   \n",
      "3 -0.50205 -2.037634  1017.8800  ... -4.170284 -3.876302 -2.466328 -3.272720   \n",
      "4 -0.41025 -1.982032  1017.8909  ... -3.925441 -4.016194 -2.607929 -3.346115   \n",
      "\n",
      "   tcc_min   tcc_max  tcc_mean  skt_min   skt_max   skt_mean  \n",
      "0      0.0  0.984451  0.293353  4.30374  26.47450  13.539474  \n",
      "1      0.0  0.983337  0.280398  4.20413  26.56630  13.528182  \n",
      "2      0.0  0.984009  0.274246  4.26760  26.59950  13.547915  \n",
      "3      0.0  0.991547  0.268021  4.27444  26.60050  13.545885  \n",
      "4      0.0  0.995331  0.254967  4.21290  26.76943  13.587671  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Aggregate to daily statistics by location\n",
    "# Group by date AND spatial coordinates to preserve location information\n",
    "agg_dict = {}\n",
    "for param in weather_params:\n",
    "    agg_dict[param] = ['min', 'max', 'mean']\n",
    "\n",
    "daily_stats = df.groupby(['date', 'latitude', 'longitude']).agg(agg_dict).reset_index()\n",
    "\n",
    "# Flatten multi-level columns\n",
    "daily_stats.columns = ['date', 'latitude', 'longitude'] + \\\n",
    "                       [f'{param}_{stat}' for param in weather_params for stat in ['min', 'max', 'mean']]\n",
    "\n",
    "print(f\"Daily aggregated data shape: {daily_stats.shape}\")\n",
    "print(f\"\\nColumns created: {daily_stats.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(daily_stats.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2458a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample location: lat=20.0, lon=-9.8, date=2025-01-01\n",
      "\n",
      "Example - t2m aggregation:\n",
      "  t2m_min: 8.08\n",
      "  t2m_max: 19.43\n",
      "  t2m_mean: 13.51\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Verify aggregation for one location\n",
    "sample_location = daily_stats.iloc[0]\n",
    "print(f\"Sample location: lat={sample_location['latitude']}, lon={sample_location['longitude']}, date={sample_location['date']}\")\n",
    "print(f\"\\nExample - t2m aggregation:\")\n",
    "print(f\"  t2m_min: {sample_location['t2m_min']:.2f}\")\n",
    "print(f\"  t2m_max: {sample_location['t2m_max']:.2f}\")\n",
    "print(f\"  t2m_mean: {sample_location['t2m_mean']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "779c2841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables to predict: ['t2m']\n",
      "Other variables will be used as features only\n",
      "\n",
      "Created 3 next-day target variables:\n",
      "['t2m_min_next', 't2m_max_next', 't2m_mean_next']\n",
      "\n",
      "Total feature columns: 21\n",
      "Target columns: 3\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Create next-day target variables (ONLY FOR VARIABLES WE WANT TO PREDICT)\n",
    "# Sort by location and date to ensure proper shifting\n",
    "daily_stats = daily_stats.sort_values(['latitude', 'longitude', 'date']).reset_index(drop=True)\n",
    "\n",
    "# IMPORTANT: Define which variables you want to PREDICT\n",
    "# Typically, you want to predict temperature (t2m)\n",
    "# Other variables (d2m, msl, u10, v10, tcc, skt) are just used as FEATURES\n",
    "\n",
    "variables_to_predict = ['t2m']  # Add more if needed: ['t2m', 'skt', 'tcc']\n",
    "\n",
    "print(f\"Variables to predict: {variables_to_predict}\")\n",
    "print(f\"Other variables will be used as features only\")\n",
    "\n",
    "# Create next-day targets ONLY for variables we want to predict\n",
    "target_cols = []\n",
    "for var in variables_to_predict:\n",
    "    for stat in ['min', 'max', 'mean']:\n",
    "        col_name = f'{var}_{stat}'\n",
    "        next_col_name = f'{var}_{stat}_next'\n",
    "        \n",
    "        # Shift within each location group\n",
    "        daily_stats[next_col_name] = daily_stats.groupby(['latitude', 'longitude'])[col_name].shift(-1)\n",
    "        target_cols.append(next_col_name)\n",
    "\n",
    "print(f\"\\nCreated {len(target_cols)} next-day target variables:\")\n",
    "print(target_cols)\n",
    "\n",
    "# Show feature columns vs target columns\n",
    "feature_cols = [col for col in daily_stats.columns \n",
    "                if col not in ['date', 'latitude', 'longitude'] and not col.endswith('_next')]\n",
    "print(f\"\\nTotal feature columns: {len(feature_cols)}\")\n",
    "print(f\"Target columns: {len(target_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a30d3663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before: 72540\n",
      "Rows after removing incomplete: 70200\n",
      "Rows removed: 2340\n",
      "\n",
      "First few rows with features and targets:\n",
      "         date  latitude  longitude   t2m_min    t2m_max   t2m_mean  \\\n",
      "0  2025-01-01      20.0       -9.8  8.079742  19.427155  13.512838   \n",
      "1  2025-01-02      20.0       -9.8  8.284332  20.229400  13.733927   \n",
      "2  2025-01-03      20.0       -9.8  8.742096  20.117584  13.730153   \n",
      "3  2025-01-04      20.0       -9.8  8.493073  19.262848  13.515086   \n",
      "4  2025-01-05      20.0       -9.8  9.574616  21.778473  14.880564   \n",
      "\n",
      "   t2m_min_next  t2m_max_next  t2m_mean_next  \n",
      "0      8.284332     20.229400      13.733927  \n",
      "1      8.742096     20.117584      13.730153  \n",
      "2      8.493073     19.262848      13.515086  \n",
      "3      9.574616     21.778473      14.880564  \n",
      "4      8.145905     22.907135      14.977478  \n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Remove rows with missing targets and inspect\n",
    "# Drop rows where any next-day target is NaN (last day for each location)\n",
    "initial_rows = len(daily_stats)\n",
    "daily_stats_complete = daily_stats.dropna(subset=target_cols).reset_index(drop=True)\n",
    "rows_removed = initial_rows - len(daily_stats_complete)\n",
    "\n",
    "print(f\"Rows before: {initial_rows}\")\n",
    "print(f\"Rows after removing incomplete: {len(daily_stats_complete)}\")\n",
    "print(f\"Rows removed: {rows_removed}\")\n",
    "print(f\"\\nFirst few rows with features and targets:\")\n",
    "print(daily_stats_complete[['date', 'latitude', 'longitude', 't2m_min', 't2m_max', 't2m_mean', \n",
    "                             't2m_min_next', 't2m_max_next', 't2m_mean_next']].head())\n",
    "\n",
    "\n",
    "\n",
    "###### REMARQUE : DO NOT FORGET TO LINK TO OTHER MONTHS LATER !!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf31526c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique locations: 2340\n",
      "\n",
      "Days per location (should be roughly equal):\n",
      "count    2340.0\n",
      "mean       30.0\n",
      "std         0.0\n",
      "min        30.0\n",
      "25%        30.0\n",
      "50%        30.0\n",
      "75%        30.0\n",
      "max        30.0\n",
      "Name: days, dtype: float64\n",
      "\n",
      "Sample locations:\n",
      "   latitude  longitude  days\n",
      "0      20.0      -9.80    30\n",
      "1      20.0      -9.55    30\n",
      "2      20.0      -9.30    30\n",
      "3      20.0      -9.05    30\n",
      "4      20.0      -8.80    30\n",
      "5      20.0      -8.55    30\n",
      "6      20.0      -8.30    30\n",
      "7      20.0      -8.05    30\n",
      "8      20.0      -7.80    30\n",
      "9      20.0      -7.55    30\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Verify spatial coverage\n",
    "unique_locations = daily_stats_complete.groupby(['latitude', 'longitude']).size().reset_index(name='days')\n",
    "print(f\"Number of unique locations: {len(unique_locations)}\")\n",
    "print(f\"\\nDays per location (should be roughly equal):\")\n",
    "print(unique_locations['days'].describe())\n",
    "print(f\"\\nSample locations:\")\n",
    "print(unique_locations.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5fbb46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved to era5_daily_features.csv\n",
      "\n",
      "============================================================\n",
      "FINAL DATASET SUMMARY\n",
      "============================================================\n",
      "Date range: 2025-01-01 to 2025-01-30\n",
      "Number of unique locations: 2340\n",
      "Total daily records: 70200\n",
      "\n",
      "Weather parameters: ['t2m', 'd2m', 'msl', 'u10', 'v10', 'tcc', 'skt']\n",
      "Features per location per day: 21 (each parameter has min/max/mean)\n",
      "Target variables: 3\n",
      "\n",
      "Column breakdown:\n",
      "  - Coordinates: latitude, longitude\n",
      "  - Date: date\n",
      "  - Current day features: 21\n",
      "  - Next day targets: 3\n",
      "  - Total columns: 27\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Save the engineered features\n",
    "daily_stats_complete.to_csv(\"era5_daily_features.csv\", index=False)\n",
    "print(\"✓ Saved to era5_daily_features.csv\")\n",
    "\n",
    "# Display comprehensive summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FINAL DATASET SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Date range: {daily_stats_complete['date'].min()} to {daily_stats_complete['date'].max()}\")\n",
    "print(f\"Number of unique locations: {len(unique_locations)}\")\n",
    "print(f\"Total daily records: {len(daily_stats_complete)}\")\n",
    "print(f\"\\nWeather parameters: {weather_params}\")\n",
    "print(f\"Features per location per day: {len(feature_cols)} (each parameter has min/max/mean)\")\n",
    "print(f\"Target variables: {len(target_cols)}\")\n",
    "print(f\"\\nColumn breakdown:\")\n",
    "print(f\"  - Coordinates: latitude, longitude\")\n",
    "print(f\"  - Date: date\")\n",
    "print(f\"  - Current day features: {len(feature_cols)}\")\n",
    "print(f\"  - Next day targets: {len(target_cols)}\")\n",
    "print(f\"  - Total columns: {len(daily_stats_complete.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d93b64ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date\\n', 'latitude\\n', 'longitude\\n', 't2m_min\\n', 't2m_max\\n',\n",
      "       't2m_mean\\n', 'd2m_min\\n', 'd2m_max\\n', 'd2m_mean\\n', 'msl_min\\n',\n",
      "       'msl_max\\n', 'msl_mean\\n', 'u10_min\\n', 'u10_max\\n', 'u10_mean\\n',\n",
      "       'v10_min\\n', 'v10_max\\n', 'v10_mean\\n', 'tcc_min\\n', 'tcc_max\\n',\n",
      "       'tcc_mean\\n', 'skt_min\\n', 'skt_max\\n', 'skt_mean\\n', 't2m_min_next\\n',\n",
      "       't2m_max_next\\n', 't2m_mean_next\\n'],\n",
      "      dtype='object')\n",
      "Index(['valid_time', 'latitude', 'longitude', 't2m', 'd2m', 'msl', 'u10',\n",
      "       'v10', 'tcc', 'skt', 'number', 'expver', 'date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(daily_stats_complete.columns + \"\\n\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99fc489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
